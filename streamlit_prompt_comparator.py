import streamlit as st
import openai
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ì‚¬ìš©ìì—ê²Œ API í‚¤ ì…ë ¥ ë°›ê¸°
user_api_key = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")

# í‚¤ê°€ ì—†ìœ¼ë©´ ì‹¤í–‰ ì¤‘ë‹¨
if not user_api_key:
    st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

# ì…ë ¥ëœ í‚¤ë¡œ ì„¤ì •
openai.api_key = user_api_key

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ê·œì¹™ì„ ì—„ê²©íˆ ë”°ë¥´ì„¸ìš”:
1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¼ê´€ëœ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
2. ë‹µë³€ì€ í•­ìƒ ê°ê´€ì ì´ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.
3. ë™ì¼í•œ ì§ˆë¬¸ì—ëŠ” í•­ìƒ ë™ì¼í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
4. ë¶ˆí•„ìš”í•œ ë³€í˜•ì´ë‚˜ ì°½ì˜ì ì¸ í‘œí˜„ì„ í”¼í•˜ì„¸ìš”."""

# ---- UI ê¾¸ë¯¸ê¸° ----
st.set_page_config(page_title="í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë¹„êµ ë„êµ¬", page_icon="ğŸ”¬", layout="wide")
st.markdown(
    """
    <style>
    .main-title {font-size: 3.5rem; font-weight: bold; margin-bottom: 0.5rem; color: #1f77b4;}
    .subtitle {font-size: 1.3rem; color: #666; margin-bottom: 1rem; font-weight: 500;}
    .desc {font-size: 1.1rem; color: #555; margin-bottom: 1.5rem; line-height: 1.6;}
    .chatbox {background: #f8f9fa; border: 1px solid #e9ecef; border-radius: 8px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 4px rgba(0,0,0,0.1);}
    .divider {height: 1px; background: #dee2e6; margin: 1.5rem 0;}
    .response-box {background: transparent; border: none; padding: 0.5rem 0; margin: 0.5rem 0; border-left: 4px solid #007bff; padding-left: 1rem;}
    .user-box {background: transparent; border: none; padding: 0.5rem 0; margin: 0.5rem 0; border-left: 4px solid #28a745; padding-left: 1rem;}
    .question-display {background: transparent; border: none; padding: 0.5rem 0; margin: 0.5rem 0; border-left: 4px solid #ffc107; padding-left: 1rem;}
    .model-selector {background: #f8f9fa; border: 1px solid #e9ecef; border-radius: 6px; padding: 1rem; margin-bottom: 1rem;}
    .input-section {background: #f8f9fa; border: 1px solid #e9ecef; border-radius: 6px; padding: 1.5rem; margin-bottom: 1rem;}
    .stButton > button {background-color: #007bff; color: white; border: none; border-radius: 4px; padding: 0.5rem 1rem; font-weight: 500;}
    .stButton > button:hover {background-color: #0056b3;}
    </style>
    """, unsafe_allow_html=True
)

# í—¤ë” ì„¹ì…˜
st.markdown('<div class="main-title">ğŸ”¬ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë¹„êµ ë¶„ì„ ë„êµ¬</div>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">LLM ëª¨ë¸ë³„ ì‘ë‹µ ì„±ëŠ¥ ë° ì¼ê´€ì„± ë¶„ì„</div>', unsafe_allow_html=True)
st.markdown(
    '<div class="desc">ì´ ë„êµ¬ëŠ” ê¸°ì—… í™˜ê²½ì—ì„œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.<br>'
    'ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹¤ì–‘í•œ LLM ëª¨ë¸ì˜ ì‘ë‹µì„ ë¹„êµí•˜ì—¬ <b>ì‘ë‹µ ì¼ê´€ì„±</b>, <b>ì •í™•ì„±</b>, <b>í’ˆì§ˆ</b>ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>'
    'í”„ë¡¬í”„íŠ¸ ìµœì í™” ë° ëª¨ë¸ ì„ íƒ ì˜ì‚¬ê²°ì •ì— í™œìš©í•˜ì„¸ìš”.</div>',
    unsafe_allow_html=True
)

# ---- ëª¨ë¸ ì„ íƒ ----
st.markdown("### ğŸ¤– ë¹„êµí•  AI ëª¨ë¸ ì„ íƒ")
model_options = [
    "gpt-3.5-turbo",
    "gpt-4o",
    "gpt-4-turbo",
    "gpt-4"
]
col_model1, col_model2 = st.columns(2)
with col_model1:
    model1 = st.selectbox("**ì²« ë²ˆì§¸ AI ëª¨ë¸**", model_options, key="model1", help="ë¹„êµí•  ì²« ë²ˆì§¸ AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”")
with col_model2:
    model2 = st.selectbox("**ë‘ ë²ˆì§¸ AI ëª¨ë¸**", model_options, key="model2", help="ë¹„êµí•  ë‘ ë²ˆì§¸ AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”")

st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

# ---- ì„¸ì…˜ ìƒíƒœ ----
if "messages1" not in st.session_state:
    st.session_state.messages1 = [{"role": "system", "content": SYSTEM_PROMPT}]
if "messages2" not in st.session_state:
    st.session_state.messages2 = [{"role": "system", "content": SYSTEM_PROMPT}]
if "response_cache" not in st.session_state:
    st.session_state.response_cache = {}
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []
if "show_input" not in st.session_state:
    st.session_state.show_input = True

def get_chat_response(prompt, messages, model):
    cache_key = f"{model}::{prompt}"
    if cache_key in st.session_state.response_cache:
        return st.session_state.response_cache[cache_key]
    response = openai.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0,
        seed=42,
        presence_penalty=0,
        frequency_penalty=0,
        top_p=1,
        max_tokens=1000
    )
    assistant_response = response.choices[0].message.content
    st.session_state.response_cache[cache_key] = assistant_response
    return assistant_response

# ---- ì§ˆë¬¸ ì…ë ¥ ----
st.markdown("### ğŸ’¬ ì§ˆë¬¸ ì…ë ¥í•˜ê¸°")

# ì…ë ¥ì°½ í‘œì‹œ/ìˆ¨ê¹€ í† ê¸€ ë²„íŠ¼
col_toggle, col_info = st.columns([1, 3])
with col_toggle:
    if st.button("ğŸ“ ì§ˆë¬¸ ì…ë ¥ì°½ ë³´ê¸°/ìˆ¨ê¸°ê¸°", key="toggle_input"):
        st.session_state.show_input = not st.session_state.show_input

if st.session_state.show_input:
    with st.form("common_form", clear_on_submit=True):
        common_prompt = st.text_area(
            "ë‘ AI ëª¨ë¸ì—ê²Œ ë™ì¼í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", 
            height=120, 
            key="common_input",
            help="ë¹„êµ ë¶„ì„ì„ ìœ„í•´ ë‘ AI ëª¨ë¸ì—ê²Œ ê°™ì€ ì§ˆë¬¸ì„ ë¬¼ì–´ë³´ì„¸ìš”. ì˜ˆ: 'ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”'"
        )
        col_submit, col_clear = st.columns(2)
        with col_submit:
            submitted = st.form_submit_button("ğŸš€ ë‘ AI ëª¨ë¸ì—ê²Œ ì§ˆë¬¸í•˜ê¸°", use_container_width=True)
        with col_clear:
            if st.form_submit_button("ğŸ—‘ï¸ ëª¨ë“  ëŒ€í™” ì§€ìš°ê¸°", use_container_width=True):
                st.session_state.conversation_history = []
                st.session_state.messages1 = [{"role": "system", "content": SYSTEM_PROMPT}]
                st.session_state.messages2 = [{"role": "system", "content": SYSTEM_PROMPT}]
                st.rerun()
        
        if submitted and common_prompt:
            # ë‘ ì±—ë´‡ì˜ ë©”ì‹œì§€ì— ì§ˆë¬¸ ì¶”ê°€
            st.session_state.messages1.append({"role": "user", "content": common_prompt})
            st.session_state.messages2.append({"role": "user", "content": common_prompt})
            
            # ë‘ ì±—ë´‡ì˜ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
            response1 = get_chat_response(common_prompt, st.session_state.messages1, model1)
            response2 = get_chat_response(common_prompt, st.session_state.messages2, model2)
            
            # ì‘ë‹µì„ ë©”ì‹œì§€ì— ì¶”ê°€
            st.session_state.messages1.append({"role": "assistant", "content": response1})
            st.session_state.messages2.append({"role": "assistant", "content": response2})
            
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            st.session_state.conversation_history.append({
                "question": common_prompt,
                "response1": response1,
                "response2": response2,
                "model1": model1,
                "model2": model2
            })
else:
    st.info("ğŸ’¡ ì§ˆë¬¸ ì…ë ¥ì°½ì´ ìˆ¨ê²¨ì ¸ ìˆìŠµë‹ˆë‹¤. 'ğŸ“ ì§ˆë¬¸ ì…ë ¥ì°½ ë³´ê¸°/ìˆ¨ê¸°ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”.")

# ---- ë¶„ì„ ê²°ê³¼ í‘œì‹œ ----
if st.session_state.conversation_history:
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    st.markdown("### ğŸ“Š ë¹„êµ ê²°ê³¼")
    
    # í†µê³„ ì •ë³´
    total_tests = len(st.session_state.conversation_history)
    st.metric("ì´ ì§ˆë¬¸ ìˆ˜", total_tests)
    
    for i, conv in enumerate(reversed(st.session_state.conversation_history)):
        st.markdown(f"#### ì§ˆë¬¸ #{len(st.session_state.conversation_history) - i}")
        
        # ì§ˆë¬¸ í‘œì‹œ (í•œ ë²ˆë§Œ)
        st.markdown('<div class="question-display">', unsafe_allow_html=True)
        if conv["question"].strip():
            st.markdown("**ğŸ’¬ ì§ˆë¬¸:**")
            st.markdown(f"> {conv['question']}")
        st.markdown('</div>', unsafe_allow_html=True)
        
        # ì‘ë‹µ í‘œì‹œ
        col1, col2 = st.columns(2)
        with col1:
            st.markdown('<div class="response-box">', unsafe_allow_html=True)
            st.markdown(f"**ğŸ¤– {conv['model1']} ë‹µë³€:**")
            st.write(conv["response1"])
            st.markdown('</div>', unsafe_allow_html=True)
        with col2:
            st.markdown('<div class="response-box">', unsafe_allow_html=True)
            st.markdown(f"**ğŸ¤– {conv['model2']} ë‹µë³€:**")
            st.write(conv["response2"])
            st.markdown('</div>', unsafe_allow_html=True)
        
        if i < len(st.session_state.conversation_history) - 1:  # ë§ˆì§€ë§‰ í•­ëª©ì´ ì•„ë‹ˆë©´ êµ¬ë¶„ì„  ì¶”ê°€
            st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

# ---- ê³ ê¸‰ ë¶„ì„ ëª¨ë“œ (ì„ íƒì‚¬í•­) ----
with st.expander("ğŸ”§ ê°œë³„ AI ëª¨ë¸ê³¼ ëŒ€í™”í•˜ê¸°"):
    st.markdown("### ê° AI ëª¨ë¸ê³¼ ê°œë³„ì ìœ¼ë¡œ ëŒ€í™”í•˜ê¸°")
    col1, col2 = st.columns(2)

    with col1:
        st.markdown(f"**{model1}ì™€ 1:1 ëŒ€í™”**")
        for message in st.session_state.messages1[1:]:
            with st.chat_message(message["role"]):
                st.write(message["content"])
        
        with st.form("form1", clear_on_submit=True):
            prompt1 = st.text_input(f"{model1}ì—ê²Œ ê°œë³„ ì§ˆë¬¸í•˜ê¸°", key="input1")
            submitted1 = st.form_submit_button("ì „ì†¡", use_container_width=True)
            if submitted1 and prompt1:
                st.session_state.messages1.append({"role": "user", "content": prompt1})
                with st.chat_message("user"):
                    st.write(prompt1)
                with st.chat_message("assistant"):
                    assistant_response = get_chat_response(prompt1, st.session_state.messages1, model1)
                    st.write(assistant_response)
                    st.session_state.messages1.append({"role": "assistant", "content": assistant_response})

    with col2:
        st.markdown(f"**{model2}ì™€ 1:1 ëŒ€í™”**")
        for message in st.session_state.messages2[1:]:
            with st.chat_message(message["role"]):
                st.write(message["content"])
        
        with st.form("form2", clear_on_submit=True):
            prompt2 = st.text_input(f"{model2}ì—ê²Œ ê°œë³„ ì§ˆë¬¸í•˜ê¸°", key="input2")
            submitted2 = st.form_submit_button("ì „ì†¡", use_container_width=True)
            if submitted2 and prompt2:
                st.session_state.messages2.append({"role": "user", "content": prompt2})
                with st.chat_message("user"):
                    st.write(prompt2)
                with st.chat_message("assistant"):
                    assistant_response = get_chat_response(prompt2, st.session_state.messages2, model2)
                    st.write(assistant_response)
                    st.session_state.messages2.append({"role": "assistant", "content": assistant_response})